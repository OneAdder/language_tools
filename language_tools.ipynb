{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xxIYsGVNli-b",
        "rZ4omtkUxhrk",
        "mfOUvhAiaXga"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_mP_C9CJZZd"
      },
      "source": [
        "# Different segmentation methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxIYsGVNli-b"
      },
      "source": [
        "## MORPHESSOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JeB1YO-06e-"
      },
      "source": [
        "!git clone https://github.com/aalto-speech/morfessor.git\n",
        "!cd morfessor && python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi5vvrWl09dA",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "23c8066c-053e-442a-e500-e7e9de64b8bf"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28543990-e2e4-452c-b9de-6cb9de2fba56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28543990-e2e4-452c-b9de-6cb9de2fba56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ru_standard_v4 to ru_standard_v4 (1)\n",
            "Saving corpus_v5.txt to corpus_v5.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wyo-ELZkv2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "276e8af5-580f-4323-c126-09a91f7e5884"
      },
      "source": [
        "!tail ru_standard_v4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "нан яра>к ынӈин ӄ>иты>ркын ыныкит ∅>ра>въэ>чг>ат>гъа>м миӈ>кы>ри мыт>рэ>н>рэӄ>эк>выт миӈ>кы>ри мыт>рэ>нты>гыт\n",
            "нанъ>яач>ьым люут ∅>лыгэ>майӈы>пэгля>ъ>э янра ∅>ир>гъ>и ӄол нэмэ вальы>м\n",
            "нан>ъяач>ьым ынӄэн гыргоч>аткын>ы>къым янра\n",
            "ынӄэ нэ>гитэ>э'>н эвын ынӄэн валы>ӈэ льо>о>∅\n",
            "ытръэч ∅>ив>ни>н тит>ъэм ∅>рэ>рэн\n",
            "ӄ>ыги>тъэм ва>е\n",
            "ы'ттъыгры>на ∅>льу>ни>н ӈэвысӄэт>∅ итэй\n",
            "эй йыӄӄэй ивкэ вулӄы>тви вайыкы мы>лёо>гъа\n",
            "чама мрэн>э нэлгинуюркыни нэ>лги>ну>йыв>мык>ы\n",
            "чама ны>лылеп>тил>ръу>ӄинэ>т элёльы>ль>этъы>м\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlfDVi3mk0Fs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bd690d0c-d233-4d17-fb17-5d61e0efb71b"
      },
      "source": [
        "!tail corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Сибирскыкэн властя гэтчылин ӈэранчывэӈ Анабарскыкэн-Оленёкскыкэн район.\n",
            "Тунгустэ, вальыт чымче гытгык Ессей, нагынрэтыӈӈонат Магазеяльа, оленёкскыкэнат-ым тунгустэ  Якутыльа.\n",
            "Воеводтэ Мангазейкэн ынкъам Якутскыкэн ӄонпыӈ нынмаравчеткэнат ыргичгу, иӈӄун ытри таӈналогпэрэӈ.\n",
            "Амынан Дежнёв гэтъивыльэтлин вагыргыт маравчеткэн амаравчеткэнано рытчык.\n",
            "Тэнмычьо, ынан ганпааӈатлен чит вальылӄыл пэнрыткогыргын боягтарыргэн оленёкскыкэ тунгусэты.\n",
            "Гэпэлӄэтлин Дежнёв 1673 гивик Москвак.\n",
            "Справка КС\n",
            "Энмэч 1736 гивик Г.\n",
            "Ф.\n",
            "Миллеоына ынанъыттыёл сибирскыкэн архивык гэльулинэт челобитныйыт (калеёттэ вагыргыт)."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J15WiwvpnT87"
      },
      "source": [
        "model1 - recursive; none  \n",
        "model2 - recursive; log  \n",
        "model3 - recursive; ones  \n",
        "model4 - viterbi; none  \n",
        "model5 - viterbi; log  \n",
        "model6 - viterbi; ones  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CbVrqXo1Ogc"
      },
      "source": [
        "!morfessor-train --logfile=log.log -r 42 -s model1.bin -d none corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY3b86Hon7Z6"
      },
      "source": [
        "!morfessor-train --logfile=log.log -r 42 -s model2.bin -d log corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajY1X88Ln9EJ"
      },
      "source": [
        "!morfessor-train --logfile=log.log -r 42 -s model3.bin -d ones corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFhYoA5yn9G7"
      },
      "source": [
        "!morfessor-train --logfile=log.log -r 42 -a viterbi -s model4.bin -d none corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc_zL_Z0n9Ja"
      },
      "source": [
        "!morfessor-train --logfile=log.log -r 42 -a viterbi -s model5.bin -d log corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLzS12R5n9Lo"
      },
      "source": [
        "!morfessor-train --logfile=log.log -r 42 -a viterbi -s model6.bin -d ones corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8haVobjDI0W4"
      },
      "source": [
        "import re\n",
        "res = open(\"ru_standard_v4_anno\", \"w\")\n",
        "with open(\"ru_standard_v4\") as f:\n",
        "  for line in f.readlines():\n",
        "    for word in line.split():\n",
        "      splitted = re.sub(\">|∅\", \" \", word)\n",
        "      clear = re.sub(\" \", \"\", splitted)\n",
        "      line = clear + \" \" + splitted + \"\\n\"\n",
        "      res.write(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EjtxAk-SIhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "64577283-bbc8-4073-d643-f1b98ab9cd69"
      },
      "source": [
        "!morfessor-evaluate ru_standard_v4_anno model1.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations from 'ru_standard_v4_anno'...\n",
            "Detected utf-8 encoding\n",
            "Done.\n",
            "Loading model from 'model1.bin'...\n",
            "Done.\n",
            "model1.bin was read as a binary model\n",
            "The test set is too small for this sample size\n",
            "Filename   : model1.bin\n",
            "Num samples: 10\n",
            "Sample size: 1000.0\n",
            "F-score    : 0.59\n",
            "Precision  : 0.686\n",
            "Recall     : 0.517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiFlT1TQGpkg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d3248f32-0b61-4c4b-bc38-d4d0728e94a2"
      },
      "source": [
        "!morfessor-evaluate ru_standard_v4_anno model2.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations from 'ru_standard_v4_anno'...\n",
            "Detected utf-8 encoding\n",
            "Done.\n",
            "Loading model from 'model2.bin'...\n",
            "Done.\n",
            "model2.bin was read as a binary model\n",
            "The test set is too small for this sample size\n",
            "Filename   : model2.bin\n",
            "Num samples: 10\n",
            "Sample size: 1000.0\n",
            "F-score    : 0.601\n",
            "Precision  : 0.69\n",
            "Recall     : 0.533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwG0hUwnnP2N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1cd60d0e-6de9-4aec-9660-9d89b862e267"
      },
      "source": [
        "!morfessor-evaluate ru_standard_v4_anno model3.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations from 'ru_standard_v4_anno'...\n",
            "Detected utf-8 encoding\n",
            "Done.\n",
            "Loading model from 'model3.bin'...\n",
            "Done.\n",
            "model3.bin was read as a binary model\n",
            "The test set is too small for this sample size\n",
            "Filename   : model3.bin\n",
            "Num samples: 10\n",
            "Sample size: 1000.0\n",
            "F-score    : 0.61\n",
            "Precision  : 0.678\n",
            "Recall     : 0.555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VafFHsRUoON4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "13f9d1ac-5477-4cb5-aa68-229a9fefdc6d"
      },
      "source": [
        "!morfessor-evaluate ru_standard_v4_anno model4.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations from 'ru_standard_v4_anno'...\n",
            "Detected utf-8 encoding\n",
            "Done.\n",
            "Loading model from 'model4.bin'...\n",
            "Done.\n",
            "model4.bin was read as a binary model\n",
            "The test set is too small for this sample size\n",
            "Filename   : model4.bin\n",
            "Num samples: 10\n",
            "Sample size: 1000.0\n",
            "F-score    : 0.508\n",
            "Precision  : 0.659\n",
            "Recall     : 0.414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEJB3DKPoO9V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4ee66917-6c32-4d9c-a64d-ceb368ad8dda"
      },
      "source": [
        "!morfessor-evaluate ru_standard_v4_anno model5.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations from 'ru_standard_v4_anno'...\n",
            "Detected utf-8 encoding\n",
            "Done.\n",
            "Loading model from 'model5.bin'...\n",
            "Done.\n",
            "model5.bin was read as a binary model\n",
            "The test set is too small for this sample size\n",
            "Filename   : model5.bin\n",
            "Num samples: 10\n",
            "Sample size: 1000.0\n",
            "F-score    : 0.528\n",
            "Precision  : 0.616\n",
            "Recall     : 0.462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_oYUyksoPgd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9f8909e1-7834-46d5-808e-fa6cf7c4c8f3"
      },
      "source": [
        "!morfessor-evaluate ru_standard_v4_anno model6.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations from 'ru_standard_v4_anno'...\n",
            "Detected utf-8 encoding\n",
            "Done.\n",
            "Loading model from 'model6.bin'...\n",
            "Done.\n",
            "model6.bin was read as a binary model\n",
            "The test set is too small for this sample size\n",
            "Filename   : model6.bin\n",
            "Num samples: 10\n",
            "Sample size: 1000.0\n",
            "F-score    : 0.534\n",
            "Precision  : 0.596\n",
            "Recall     : 0.484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ4omtkUxhrk"
      },
      "source": [
        "## BasilisAndr/chkchn - issue with metrics, got no answer from the creator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSZc_kXpss5b"
      },
      "source": [
        "!git clone https://github.com/BasilisAndr/chkchn.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Lb12hKxuoT"
      },
      "source": [
        "!rm chkchn/corpora/ckt.crp.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u_KylYKzt_L"
      },
      "source": [
        "!mv corpus_v4.txt chkchn/corpora/ckt.crp.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR3Biibnz0dt"
      },
      "source": [
        "!cd chkchn && autoconf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi-L5aGl8Ep7"
      },
      "source": [
        "!apt-get install autoconf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY3UG2zbz10G"
      },
      "source": [
        "!apt-get install automake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNB_SD2G2M_E"
      },
      "source": [
        "!git clone https://github.com/hfst/hfst.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iex5PWR56Dat"
      },
      "source": [
        "!apt-get install libtool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAwoNkyk8S0I"
      },
      "source": [
        "!apt-get install bison flex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyFpl_SI5obk"
      },
      "source": [
        "!cd hfst/ && ./autogen.sh && ./configure --enable-all-tools && make && make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ3HiGtdz88n"
      },
      "source": [
        "!cd chkchn && ./autogen.sh && autoconf && automake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Zgr_nzBIK0"
      },
      "source": [
        "!cd chkchn && ./configure && make && make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKTsQ-SA9hY"
      },
      "source": [
        "!ldconfig -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrtzoC-3Ft3K"
      },
      "source": [
        "!apt-get install apertium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpLrVLdxF-Zd"
      },
      "source": [
        "!apt-get install apcalc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w2ZnV7x6OLd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "c2209e5d-2905-432e-b45f-a6c234555562"
      },
      "source": [
        "!cd chkchn/scripts && ./corpus-stat.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokenised words in the corpus: 10610\n",
            "Number of known words in the corpus: 2431\n",
            "Top known words in the corpus:\n",
            "    402 ^э/э<ij>$\n",
            "    166 ^ынӄэн/ынӄэн<prn><dem><sg><abs>$\n",
            "    121 ^'/'<apos>$\n",
            "     97 ^гым/гым<prn><pers><p1><sg><abs>$\n",
            "     64 ^ин/ёк<v><tv><ger><poss><3sg><sg><abs>$\n",
            "     57 ^гэ/гыԓгын<n><erg>$\n",
            "     53 ^эты/эты<part>$\n",
            "     51 ^мури/мури<prn><pers><p1><pl><abs>$\n",
            "     46 ^ынӄо/ынӄо<adv>/ынӄо<cnjcoo>$\n",
            "     44 ^ынкъам/ынкъам<cnjcoo>$\n",
            "Coverage: \t22.9 %\n",
            "Top unknown words in the corpus:\n",
            "    566 ^н/*н$\n",
            "    405 ^т/*т$\n",
            "    214 ^ъым/*ъым$\n",
            "    211 ^ны/*ны$\n",
            "    195 ^к/*к$\n",
            "    105 ^ӄин/*ӄин$\n",
            "     99 ^нэ/*нэ$\n",
            "     90 ^кы/*кы$\n",
            "     88 ^и/*и$\n",
            "     87 ^а/*а$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF9EnWEjBnOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c012992-1882-4f62-cfc3-05552de1eeec"
      },
      "source": [
        "!echo \"token\" | hfst-lookup ckt.mor.hfst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hfst-lookup: Could not open 'ckt.mor.hfst'. : No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUcfdcEZGTP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "cb218aa5-5e58-4398-81c6-484e4a8d0262"
      },
      "source": [
        "!head chkchn/corpora/corpus-stat-res.txt -n 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^Амаравкэваратэн/*Амаравкэваратэн$\n",
            "^таа’койӈын/*таа’койӈын$\n",
            "^./.<sent>$\n",
            "^Йъйыӄык/*Йъйыӄык$\n",
            "^ныӄэлпэратӄэн/*ныӄэлпэратӄэн$\n",
            "^вытэчгытрыӄэргыльын/*вытэчгытрыӄэргыльын$\n",
            "^йыӈэттэт/йыӈэттэт<n><sg><abs>$\n",
            "^./.<sent>$\n",
            "^Мыкыӈ/*Мыкыӈ$\n",
            "^нывытрэтӄин/вырвыр<incorp>+рэк<v><tv><th><stat><hab><a_pl3><o_sg3>/вырвыр<incorp>+рэтык<v><tv><stat><hab><a_pl3><o_sg3>/вытвыт<incorp>+рэк<v><tv><th><stat><hab><a_pl3><o_sg3>/вытвыт<incorp>+рэтык<v><tv><stat><hab><a_pl3><o_sg3>/вытрэтык<v><iv><stat><hab><s_sg3>$\n",
            "^челгатвытрыльо/*челгатвытрыльо$\n",
            "^,/,<cm>$\n",
            "^ынӄоры/ынӄоры<adv>$\n",
            "^-/-<guio>$\n",
            "^ым/ым<part>$\n",
            "^вытэчгытрыльо/*вытэчгытрыльо$\n",
            "^./.<sent>$\n",
            "^Ынӄоры/Ынӄоры<adv>$\n",
            "^-/-<guio>$\n",
            "^ым/ым<part>$\n",
            "^ныӄэргавыӈоӄэн/*ныӄэргавыӈоӄэн$\n",
            "^нычелгъав/*нычелгъав$\n",
            "^./.<sent>$\n",
            "^Ы'льыле/*Ы'льыле$\n",
            "^ыннаны/ыннаны<adv>$\n",
            "^гэнниӈэвлин/*гэнниӈэвлин$\n",
            "^аэродром/*аэродром$\n",
            "^,/,<cm>$\n",
            "^элгыкъалейпыгъат/*элгыкъалейпыгъат$\n",
            "^пылвынтымытӄыёчгыт/*пылвынтымытӄыёчгыт$\n",
            "^эвыр/эвыр<cnjcoo>$\n",
            "^оттыраӄагтэ/*оттыраӄагтэ$\n",
            "^,/,<cm>$\n",
            "^ы'льыл/*ы'льыл$\n",
            "^нэмыӄэй/нэмыӄэй<adv>$\n",
            "^ӄынур/ӄынур<adv>$\n",
            "^амалваӈ/*амалваӈ$\n",
            "^нынъэлӄин/*нынъэлӄин$\n",
            "^:/:<sent>$\n",
            "^нычелгатӄэн/*нычелгатӄэн$\n",
            "^,/,<cm>$\n",
            "^нывытэчгытратӄэн/вытэчгытратык<v><iv><stat><hab><s_sg3>/вытэчгытратык<v><tv><stat><hab><a_pl3><o_sg3>$\n",
            "^./.<sent>$\n",
            "^Аэродромык/*Аэродромык$\n",
            "^рымагты/рымагтыкэн<adj><3sg>/рымэк<v><iv><vb>/рымэк<v><tv><vb>$\n",
            "^нувпэраӄэн/*нувпэраӄэн$\n",
            "^гытгын/гытгын<n><aa><ess>/гытгын<n><px3sg><abs>/гытгын<n><sg><abs>$\n",
            "^,/,<cm>$\n",
            "^пытӄы/пытӄы<adv>$\n",
            "^рымагты/рымагтыкэн<adj><3sg>/рымэк<v><iv><vb>/рымэк<v><tv><vb>$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yGV5M41WGKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "34b6e8e7-db02-4c5f-bf1b-510a4bf48892"
      },
      "source": [
        "!head chkchn/corpora/ckt.crp.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Амаравкэваратэн таа’койӈын.\n",
            "Йъйыӄык ныӄэлпэратӄэн вытэчгытрыӄэргыльын йыӈэттэт.\n",
            "Мыкыӈ нывытрэтӄин челгатвытрыльо, ынӄоры-ым вытэчгытрыльо.\n",
            "Ынӄоры-ым ныӄэргавыӈоӄэн нычелгъав.\n",
            "Ы'льыле ыннаны гэнниӈэвлин аэродром, элгыкъалейпыгъат пылвынтымытӄыёчгыт эвыр оттыраӄагтэ, ы'льыл нэмыӄэй ӄынур амалваӈ нынъэлӄин: нычелгатӄэн, нывытэчгытратӄэн.\n",
            "Аэродромык рымагты нувпэраӄэн гытгын, пытӄы рымагты нывытрэтӄинэт маёлгыт.\n",
            "Ынӈытэӄ наӄам чит гакыткытръолен, маёлгэпы гапыльыльатыӈоленат вээмӄэгти, ы'льыл гатылгыӈӈолен, гытгын энмэч уйӈэ эгилкэ гэнъэтлин.\n",
            "Люур нэмэ маччьачаӈатыӈогъэ, энмэч ӈыронъылёк лёӈпаата пиӈэтык, ӄынур нэмэ льэлеӈръугъи, э'квырга-ым гытгын ӄонпы гапаален ӄитык.\n",
            "гатылгыӈӈолен, гытгын энмэч уйӈэ эгилкэ гэнъэтлин.\n",
            "Люур нэмэ маччьачаӈатыӈогъэ, энмэч ӈыронъылёк лёӈпаата пиӈэтык, ӄынур нэмэ льэлеӈръугъи, э'квырга-ым гытгын ӄонпы гапаален ӄитык.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhK-QA0VWR59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "908e2a5d-32bd-4d0a-e28e-cabc6c42f748"
      },
      "source": [
        "!cd chkchn && echo \"ыʼныгтыгыт\" | hfst-lookup ckt.mor.hfst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hfst-lookup: warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\n",
            "Using HFST basic transducer format and performing slow lookups\n",
            "> ыʼныгтыгыт\tыʼныгтыгыт+?\tinf\n",
            "\n",
            "> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfOUvhAiaXga"
      },
      "source": [
        "## AlexeySorokin/NeuralMorphemeSegmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l3DKBo9YVYs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2524776e-361f-4608-f9d7-bd4b2d988913"
      },
      "source": [
        "!git clone https://github.com/AlexeySorokin/NeuralMorphemeSegmentation.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NeuralMorphemeSegmentation'...\n",
            "remote: Enumerating objects: 234, done.\u001b[K\n",
            "remote: Total 234 (delta 0), reused 0 (delta 0), pack-reused 234\u001b[K\n",
            "Receiving objects: 100% (234/234), 39.47 MiB | 13.68 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjsMIBfmafhf",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5b62958e-ca83-46f4-b7ad-11e2248b55b9"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e78bc657-34b7-42fa-8ecd-4658ad308635\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e78bc657-34b7-42fa-8ecd-4658ad308635\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving config.json to config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lej1Os3FbbG8"
      },
      "source": [
        "!mv config.json NeuralMorphemeSegmentation/config/config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSMN55LvbSrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b51a6d34-d0d7-4d16-fe93-7915b82b045b"
      },
      "source": [
        "!head ru_standard_v4_anno"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "гымнин гым нин\n",
            "ытльат ытльа т\n",
            "ы'ттъуви ы'ттъуви  \n",
            "ынкъам ынкъам\n",
            "о'мрытваал о'мрытваал  \n",
            "пууръу пууръу\n",
            "эпы эпы  \n",
            "гымнин гым нин\n",
            "о'м о'м\n",
            "о'мрыквот о'мрыквот  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "930PXB5rbasc"
      },
      "source": [
        "train = open(\"NeuralMorphemeSegmentation/data/chkchn.train\", \"w\")\n",
        "dev = open(\"NeuralMorphemeSegmentation/data/chkchn.dev\", \"w\")\n",
        "data = []\n",
        "with open(\"ru_standard_v4_anno\") as f:\n",
        "  for line in f.readlines():\n",
        "    newline = \"\"\n",
        "    words = line.split()\n",
        "    newline = words[0] + '\\t' + '/'.join(words[1:]) + \"\\n\"\n",
        "    data.append(newline)\n",
        "data, _ = shuffle(data, data, random_state=42)\n",
        "divider = int(len(data)*0.9)\n",
        "train.writelines(data[:divider])\n",
        "dev.writelines(data[divider:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjlYEdMZd4fF"
      },
      "source": [
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnPSmLQ2dp6Z"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && sed -i 's/adam/Adam/g' neural_morph_segm.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvvEnLjnef4A"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && mkdir results && cd results && touch test-chkchn.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlrOlMVbdpl3"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config.json # 83.67"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZHnvyO-rH-9"
      },
      "source": [
        "import json\n",
        "def config_maker(path, layers, window, filters, units):\n",
        "  data = {\"train_file\":\"data/chkchn.train\",\n",
        "          \"dev_file\":\"data/chkchn.dev\",\n",
        "          \"use_morpheme_types\":False,\n",
        "          \"model_params\":{\n",
        "              \"conv_layers\": layers,\n",
        "              \"window_size\": window,\n",
        "              \"filters_number\": filters,\n",
        "              \"dense_output_units\": units,\n",
        "              \"nepochs\": 75,\n",
        "              \"validation_split\": 0.2,\n",
        "              \"early_stopping\": 10,\n",
        "              \"to_memorize_morphemes\": True,\n",
        "              \"dropout\": 0.3,\n",
        "              \"to_memorize_ngram_counts\": False,\n",
        "              \"context_dropout\": 0.2, \n",
        "              \"models_number\": 1\n",
        "          },\n",
        "          \"save_file\":\"models/morphemes-chkchn.json\",\n",
        "          \"model_file\":\"models/morphemes-model-chkchn.hdf5\",\n",
        "          \"test_file\":\"data/chkchn.dev\",\n",
        "          \"outfile\":\"results/test-chkchn.txt\",\n",
        "          \"output_probs\":False,\n",
        "          \"output_morpheme_types\":False,\n",
        "          }\n",
        "  with open(path, 'w') as outfile:\n",
        "      json.dump(data, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0iPsEmgAr6X"
      },
      "source": [
        "config_maker(\"NeuralMorphemeSegmentation/config/config_1.json\", 1, [3,5], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_2.json\", 2, [3,5], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3.json\", 3, [3,5], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_4.json\", 4, [3,5], 96, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPlod2-pBCqb"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_1.json #80.71"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rLQ5QNBBXav"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_2.json # 84.55"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Ih4vqFBYze"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3.json # 86.48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_PDaoc7BZn_"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_4.json # 86.28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plAP239uBaa0"
      },
      "source": [
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_1.json\", 3, [1,2], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_2.json\", 3, [1,3], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_3.json\", 3, [2,3], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_4.json\", 3, [2,4], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_5.json\", 3, [2,4], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_6.json\", 3, [3,4], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_7.json\", 3, [3,5], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_8.json\", 3, [4,5], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9.json\", 3, [4,6], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_10.json\", 3, [1,4], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_11.json\", 3, [2,5], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_12.json\", 3, [3,6], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_13.json\", 3, [4,7], 96, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPXOSH_ANvZ-"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_1.json # 74.96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yahJL-o0NyjC"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_2.json # 85.30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C8qMhCeNzi4"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_3.json # 83.33"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzBCgN45N0ZE"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_4.json # 83.97"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNOOOQAxN1BE"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_5.json # 84.59"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKT6OckRN1mo"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_6.json # 84.26"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nisaHpQDN2I8"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_7.json # 83.88"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE42tRI_N25j"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_8.json # 85.28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXfUQ_9RN3oh"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9.json # 86.60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb3JtAWjN4TG"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_10.json # 85.02"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh-7NJGqN449"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_11.json # 85.27"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je1stMeJN6kh"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_12.json # 85.32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uchVUQNQN7JS"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_13.json # 83.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H4p-ZUEN7pD"
      },
      "source": [
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_1.json\", 3, [4,6], 50, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_2.json\", 3, [4,6], 65, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_3.json\", 3, [4,6], 80, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_4.json\", 3, [4,6], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_5.json\", 3, [4,6], 110, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_6.json\", 3, [4,6], 125, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqbWfMKsWa6l"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_1.json # 85.80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwHWdU5lWf6m"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_2.json # 82.93"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwsPCSn4WhEN"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_3.json # 82.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN7JtR0uWh5T"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_4.json # 86.24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOW5Pik4WjKV"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_5.json # 83.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWuP2inWj-r"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_6.json # 85.43"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2fpH_8nWkwz"
      },
      "source": [
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_4_1.json\", 3, [4,6], 96, 20)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_4_2.json\", 3, [4,6], 96, 35)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_4_3.json\", 3, [4,6], 96, 50)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_4_4.json\", 3, [4,6], 96, 64)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_4_5.json\", 3, [4,6], 96, 80)\n",
        "config_maker(\"NeuralMorphemeSegmentation/config/config_3_9_4_6.json\", 3, [4,6], 96, 95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDQ9Ml6SbSUs"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_4_1.json # 84.81"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeZPqA2ybWSy"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_4_2.json # 85.42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOge8-yzbXT7"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_4_3.json # 85.43"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cLFCstIbYFa"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_4_4.json # 86.04"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx5ytApObYuz"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_4_5.json # 86.70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3WAA7PObZbG"
      },
      "source": [
        "!cd NeuralMorphemeSegmentation && python neural_morph_segm.py config/config_3_9_4_6.json # 85.23"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYFdKx-gBM18"
      },
      "source": [
        "## NCRFpp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5YrJAkibaFW"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8yP4LZSBRjI",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "0a98688e-8d4b-4cbe-e3d6-9280721e1706"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e1e686f7-5b2c-4624-9a89-4833563c926b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e1e686f7-5b2c-4624-9a89-4833563c926b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ru_standard_v4 to ru_standard_v4\n",
            "Saving corpus_v4.txt to corpus_v4.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeRSv7IsBVQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5153841c-366c-43ce-d7e0-c863e8063786"
      },
      "source": [
        "!git clone https://github.com/gregarshinov/NCRFpp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NCRFpp'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 776 (delta 77), reused 70 (delta 35), pack-reused 658\u001b[K\n",
            "Receiving objects: 100% (776/776), 6.91 MiB | 4.87 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZrkVkjcBnhR"
      },
      "source": [
        "!mkdir corpora && mv ru_standard_v4 corpora/ru_standard_v4 && mv corpus_v5.txt corpora/corpus_v5.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cmw9AOvBz4O"
      },
      "source": [
        "!mkdir segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiTXBwMnBie4"
      },
      "source": [
        "CORPUS_HOME = Path(\"/content/corpora\")\n",
        "CORPUS_NAME = \"ru_standard_v4\"\n",
        "OUT_FOLDER_PATH = Path(\"segmentation\")\n",
        "OUT_FOLDER_PATH.mkdir(exist_ok=True)\n",
        "CWD = Path.cwd()\n",
        "N_SPLITS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTjm1WWaCJ7J"
      },
      "source": [
        "CONFIG_TEMPLATE = '''train_dir={train_path}\n",
        "dev_dir={test_path}\n",
        "test_dir={test_path}\n",
        "model_dir={model_path}\n",
        "log_dir={log_path}\n",
        "seg=True\n",
        "char_emb_dim=30\n",
        "use_crf=True\n",
        "use_char=True\n",
        "word_seq_feature=CNN\n",
        "char_seq_feature=CNN\n",
        "nbest=1\n",
        "status=train\n",
        "optimizer=SGD\n",
        "iteration=1000\n",
        "batch_size=10\n",
        "ave_batch_loss=False\n",
        "cnn_layer=4\n",
        "char_hidden_dim=50\n",
        "dropout=0.5\n",
        "lstm_layer=0\n",
        "bilstm=False\n",
        "learning_rate=0.015\n",
        "lr_decay=0.05\n",
        "momentum=0\n",
        "l2=1e-8\n",
        "gpu=True'''\n",
        "DECODE_CONFIG_TEMPLATE = '''status=decode\n",
        "raw_dir={raw_dir}\n",
        "nbest=1\n",
        "decode_dir={decode_dir}\n",
        "dset_dir={dset_dir}\n",
        "load_model_dir={model_dir}'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLiC52B8CKgF"
      },
      "source": [
        "with open(CORPUS_HOME.joinpath(CORPUS_NAME)) as corpus_file:\n",
        "    sentences = [line.rstrip() for line in corpus_file]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzxLNlaGCOAW"
      },
      "source": [
        "tokens = [word for line in sentences for word in line.split()]\n",
        "types = Counter(tokens)\n",
        "morphemes = [morph for word in types for morph in word.split(\">\")]\n",
        "morph_stats = Counter(morphemes)\n",
        "rare_morphemes = {morph for morph in morph_stats if morph_stats[morph] < 2}\n",
        "representative_words = [word for word in types if not set(word.split(\">\")).intersection(rare_morphemes)]\n",
        "words_df = pd.DataFrame(representative_words, columns=[\"word\"])\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m96TwKhCPdJ"
      },
      "source": [
        "B = \"B-MORPH\"\n",
        "M = \"M-MORPH\"\n",
        "E = \"E-MORPH\"\n",
        "S = \"S-MORPH\"\n",
        "\n",
        "def label(word):\n",
        "    target = \"\"\n",
        "    morphemes = word.split(\">\")\n",
        "    for morph in morphemes:\n",
        "        if morph:\n",
        "            morph_len = len(morph)\n",
        "            if morph_len == 1:\n",
        "                target += f\"{morph} {S}\\n\"\n",
        "            else:\n",
        "                target += f\"{morph[0]} {B}\\n\"\n",
        "                for ch_idx in range(1, morph_len - 1):\n",
        "                    target += f\"{morph[ch_idx]} {M}\\n\"\n",
        "                target += f\"{morph[-1]} {E}\\n\"\n",
        "    return target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v58abwDCjl3"
      },
      "source": [
        "for idx, (train, test) in enumerate(kfold.split(words_df.index)):\n",
        "    idx += 1\n",
        "    train_words = words_df.loc[train].word\n",
        "    test_words = words_df.loc[test].word\n",
        "    fold_path = OUT_FOLDER_PATH.joinpath(f\"fold_{idx}\")\n",
        "    fold_path.mkdir(parents=True, exist_ok=True)\n",
        "    train_path = fold_path.joinpath(\"train.bmes\")\n",
        "    test_path = fold_path.joinpath(\"test.bmes\")\n",
        "    config_path = fold_path.joinpath(\"hparams.config\")\n",
        "    model_path = fold_path.joinpath(\"model\")\n",
        "    log_path = fold_path.joinpath(\"training.log\")\n",
        "    with open(config_path, \"w\") as config_file:\n",
        "        config_file.write(CONFIG_TEMPLATE.format(train_path=train_path.absolute(),\n",
        "                                                 test_path=test_path.absolute(), \n",
        "                                                 model_path=model_path.absolute(),\n",
        "                                                 log_path=log_path.absolute()))\n",
        "    for fraction_path, fraction in zip((train_path, test_path), (train_words, test_words)):\n",
        "        with open(fraction_path, \"w\") as file:\n",
        "            file.writelines(label(word) + \"\\n\" for word in fraction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrwwPdjHCnco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "38a73c9d-6ed2-49d5-a00f-6cbdd067ec35"
      },
      "source": [
        "!ls -la segmentation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 48\n",
            "drwxr-xr-x 12 root root 4096 Oct  6 08:40 .\n",
            "drwxr-xr-x  1 root root 4096 Oct  6 08:40 ..\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_1\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_10\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_2\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_3\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_4\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_5\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_6\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_7\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_8\n",
            "drwxr-xr-x  2 root root 4096 Oct  6 08:40 fold_9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDYtAUCQCqN-"
      },
      "source": [
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "def process_line(line):\n",
        "  return \"\".join(ch.lower() + \" S-MORPH\\n\" if ch != \" \" else \"\\n\\n\" for ch in line if ch not in punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O96Fd85qCxKl"
      },
      "source": [
        "with open(CORPUS_HOME.joinpath(\"corpus_v5.txt\")) as txt_corpus, open(CORPUS_HOME.joinpath(\"corpus_v5.raw\"), \"w\") as raw_file:\n",
        "  for line in txt_corpus:\n",
        "    raw_file.write(process_line(line.strip()) + \"\\n\\n.\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngs4-RH8C0Cq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cf2a4af4-7741-4863-deeb-51e4bf6bf620"
      },
      "source": [
        "!ls -la corpora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 15460\n",
            "drwxr-xr-x 2 root root     4096 Oct  6 08:40 .\n",
            "drwxr-xr-x 1 root root     4096 Oct  6 08:40 ..\n",
            "-rw-r--r-- 1 root root 13194260 Oct  6 08:40 corpus_v4.raw\n",
            "-rw-r--r-- 1 root root  2541392 Oct  6 08:40 corpus_v4.txt\n",
            "-rw-r--r-- 1 root root    79479 Oct  6 08:40 ru_standard_v4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeGmqsdVDVg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "360801cd-0738-4f4e-d359-916b22c4c073"
      },
      "source": [
        "!pip install torch==1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K     |████████████████████████████████| 591.8MB 30kB/s \n",
            "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed torch-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsgwnGODD7il"
      },
      "source": [
        "!touch segmentation/fold_1/log.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aoi3R1_Dju9"
      },
      "source": [
        "!python NCRFpp/main.py --config segmentation/fold_1/hparams.config > segmentation/fold_1/log.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clnzChqZSxbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585ad6b7-1e0a-46fd-fad8-d1a17be6fc00"
      },
      "source": [
        "!cat segmentation/fold_1/log.log | grep 'best'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exceed previous best f score: -10\n",
            "Save current best model in file: /content/segmentation/fold_1/model.0.model\n",
            "Exceed previous best f score: 0.3469785575048733\n",
            "Save current best model in file: /content/segmentation/fold_1/model.1.model\n",
            "Exceed previous best f score: 0.3651626442812172\n",
            "Save current best model in file: /content/segmentation/fold_1/model.2.model\n",
            "Exceed previous best f score: 0.4556451612903226\n",
            "Save current best model in file: /content/segmentation/fold_1/model.3.model\n",
            "Exceed previous best f score: 0.4576098059244126\n",
            "Save current best model in file: /content/segmentation/fold_1/model.5.model\n",
            "Exceed previous best f score: 0.5206286836935168\n",
            "Save current best model in file: /content/segmentation/fold_1/model.8.model\n",
            "Exceed previous best f score: 0.531062124248497\n",
            "Save current best model in file: /content/segmentation/fold_1/model.10.model\n",
            "Exceed previous best f score: 0.5614754098360656\n",
            "Save current best model in file: /content/segmentation/fold_1/model.12.model\n",
            "Exceed previous best f score: 0.583078491335372\n",
            "Save current best model in file: /content/segmentation/fold_1/model.13.model\n",
            "Exceed previous best f score: 0.5835095137420718\n",
            "Save current best model in file: /content/segmentation/fold_1/model.15.model\n",
            "Exceed previous best f score: 0.6071428571428571\n",
            "Save current best model in file: /content/segmentation/fold_1/model.16.model\n",
            "Exceed previous best f score: 0.6135922330097088\n",
            "Save current best model in file: /content/segmentation/fold_1/model.17.model\n",
            "Exceed previous best f score: 0.6300813008130082\n",
            "Save current best model in file: /content/segmentation/fold_1/model.19.model\n",
            "Exceed previous best f score: 0.6509803921568627\n",
            "Save current best model in file: /content/segmentation/fold_1/model.24.model\n",
            "Exceed previous best f score: 0.6551373346897253\n",
            "Save current best model in file: /content/segmentation/fold_1/model.26.model\n",
            "Exceed previous best f score: 0.6598569969356487\n",
            "Save current best model in file: /content/segmentation/fold_1/model.27.model\n",
            "Exceed previous best f score: 0.6694214876033058\n",
            "Save current best model in file: /content/segmentation/fold_1/model.32.model\n",
            "Exceed previous best f score: 0.7002012072434608\n",
            "Save current best model in file: /content/segmentation/fold_1/model.34.model\n",
            "Exceed previous best f score: 0.7038883349950149\n",
            "Save current best model in file: /content/segmentation/fold_1/model.37.model\n",
            "Exceed previous best f score: 0.711830131445905\n",
            "Save current best model in file: /content/segmentation/fold_1/model.40.model\n",
            "Exceed previous best f score: 0.7120315581854044\n",
            "Save current best model in file: /content/segmentation/fold_1/model.41.model\n",
            "Exceed previous best f score: 0.7193515704154003\n",
            "Save current best model in file: /content/segmentation/fold_1/model.43.model\n",
            "Exceed previous best f score: 0.7418397626112759\n",
            "Save current best model in file: /content/segmentation/fold_1/model.48.model\n",
            "Exceed previous best f score: 0.7555110220440882\n",
            "Save current best model in file: /content/segmentation/fold_1/model.49.model\n",
            "Exceed previous best f score: 0.766\n",
            "Save current best model in file: /content/segmentation/fold_1/model.51.model\n",
            "Exceed previous best f score: 0.7665995975855131\n",
            "Save current best model in file: /content/segmentation/fold_1/model.52.model\n",
            "Exceed previous best f score: 0.7704752275025278\n",
            "Save current best model in file: /content/segmentation/fold_1/model.56.model\n",
            "Exceed previous best f score: 0.7782258064516129\n",
            "Save current best model in file: /content/segmentation/fold_1/model.57.model\n",
            "Exceed previous best f score: 0.7794561933534744\n",
            "Save current best model in file: /content/segmentation/fold_1/model.58.model\n",
            "Exceed previous best f score: 0.7828685258964143\n",
            "Save current best model in file: /content/segmentation/fold_1/model.62.model\n",
            "Exceed previous best f score: 0.7879396984924624\n",
            "Save current best model in file: /content/segmentation/fold_1/model.71.model\n",
            "Exceed previous best f score: 0.8016112789526686\n",
            "Save current best model in file: /content/segmentation/fold_1/model.76.model\n",
            "Exceed previous best f score: 0.8071570576540755\n",
            "Save current best model in file: /content/segmentation/fold_1/model.77.model\n",
            "Exceed previous best f score: 0.8099502487562188\n",
            "Save current best model in file: /content/segmentation/fold_1/model.80.model\n",
            "Exceed previous best f score: 0.8188188188188189\n",
            "Save current best model in file: /content/segmentation/fold_1/model.84.model\n",
            "Exceed previous best f score: 0.8262626262626263\n",
            "Save current best model in file: /content/segmentation/fold_1/model.88.model\n",
            "Exceed previous best f score: 0.8276553106212425\n",
            "Save current best model in file: /content/segmentation/fold_1/model.104.model\n",
            "Exceed previous best f score: 0.8282025819265143\n",
            "Save current best model in file: /content/segmentation/fold_1/model.105.model\n",
            "Exceed previous best f score: 0.8289738430583501\n",
            "Save current best model in file: /content/segmentation/fold_1/model.119.model\n",
            "Exceed previous best f score: 0.8431568431568431\n",
            "Save current best model in file: /content/segmentation/fold_1/model.163.model\n",
            "Exceed previous best f score: 0.8469184890656064\n",
            "Save current best model in file: /content/segmentation/fold_1/model.203.model\n",
            "Exceed previous best f score: 0.8478260869565217\n",
            "Save current best model in file: /content/segmentation/fold_1/model.241.model\n",
            "Exceed previous best f score: 0.853174603174603\n",
            "Save current best model in file: /content/segmentation/fold_1/model.244.model\n",
            "Exceed previous best f score: 0.8545816733067729\n",
            "Save current best model in file: /content/segmentation/fold_1/model.264.model\n",
            "Exceed previous best f score: 0.8548707753479124\n",
            "Save current best model in file: /content/segmentation/fold_1/model.271.model\n",
            "Exceed previous best f score: 0.8565697091273821\n",
            "Save current best model in file: /content/segmentation/fold_1/model.285.model\n",
            "Exceed previous best f score: 0.8571428571428571\n",
            "Save current best model in file: /content/segmentation/fold_1/model.299.model\n",
            "Exceed previous best f score: 0.8577114427860696\n",
            "Save current best model in file: /content/segmentation/fold_1/model.302.model\n",
            "Exceed previous best f score: 0.86\n",
            "Save current best model in file: /content/segmentation/fold_1/model.326.model\n",
            "Exceed previous best f score: 0.8605577689243028\n",
            "Save current best model in file: /content/segmentation/fold_1/model.327.model\n",
            "Exceed previous best f score: 0.8628628628628628\n",
            "Save current best model in file: /content/segmentation/fold_1/model.380.model\n",
            "Exceed previous best f score: 0.8683417085427136\n",
            "Save current best model in file: /content/segmentation/fold_1/model.397.model\n",
            "Exceed previous best f score: 0.8703517587939699\n",
            "Save current best model in file: /content/segmentation/fold_1/model.411.model\n",
            "Exceed previous best f score: 0.8721047331319234\n",
            "Save current best model in file: /content/segmentation/fold_1/model.420.model\n",
            "Exceed previous best f score: 0.8748748748748749\n",
            "Save current best model in file: /content/segmentation/fold_1/model.443.model\n",
            "Exceed previous best f score: 0.8786359077231695\n",
            "Save current best model in file: /content/segmentation/fold_1/model.638.model\n",
            "Exceed previous best f score: 0.8795180722891567\n",
            "Save current best model in file: /content/segmentation/fold_1/model.781.model\n",
            "Exceed previous best f score: 0.8797595190380761\n",
            "Save current best model in file: /content/segmentation/fold_1/model.825.model\n",
            "Exceed previous best f score: 0.8804020100502512\n",
            "Save current best model in file: /content/segmentation/fold_1/model.863.model\n",
            "Exceed previous best f score: 0.8815261044176708\n",
            "Save current best model in file: /content/segmentation/fold_1/model.868.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yChh51GwC3uQ"
      },
      "source": [
        "config_params = {\"model_dir\": OUT_FOLDER_PATH.joinpath(\"fold_1\").joinpath(\"model.868.model\").absolute(),\n",
        "                 \"dset_dir\": OUT_FOLDER_PATH.joinpath(\"fold_1\").joinpath(\"model.dset\").absolute(),\n",
        "                 \"decode_dir\": OUT_FOLDER_PATH.joinpath(\"fold_1\").joinpath(\"corpus_v5_segmented.bmes\").absolute(),\n",
        "                 \"raw_dir\": CORPUS_HOME.joinpath(\"corpus_v5.raw\").absolute()}\n",
        "with open(OUT_FOLDER_PATH.joinpath(\"fold_1\").joinpath(\"decode.config\").absolute(), \"w\") as config_file:\n",
        "  config_file.write(DECODE_CONFIG_TEMPLATE.format(**config_params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI5PhAoFpIjY"
      },
      "source": [
        "!python NCRFpp/main.py --config segmentation/fold_1/decode.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxi_eVXrwqTb"
      },
      "source": [
        "!head segmentation/fold_1/corpus_v5_segmented.bmes -n 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuXHR4enpJN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dd8c7-52db-4286-bb59-50b2686175ac"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"segmentation/fold_1/corpus_v5_segmented.bmes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d2fbe44d-4fa5-4575-9c9a-00ae296e46ea\", \"corpus_v5_segmented.bmes\", 14943111)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QvHHNIYyKN1"
      },
      "source": [
        "import re\n",
        "segmented_words = []\n",
        "with open(\"segmentation/fold_1/corpus_v5_segmented.bmes\") as f:\n",
        "  word = ''\n",
        "  for l in f.readlines():\n",
        "    if re.match('^[\\s\\n]*$', l) and word != '':\n",
        "      segmented_words.append(word.strip(\">\").replace(\">>\", \">\"))\n",
        "      word = ''\n",
        "      continue\n",
        "    try:\n",
        "      ch, typ = l.split()\n",
        "      if typ == \"B-MORPH\":\n",
        "        word += \">\" + ch\n",
        "      if typ == \"E-MORPH\":\n",
        "        word += ch + \">\"\n",
        "      if typ == \"S-MORPH\":\n",
        "        word += \">\" + ch + \">\"\n",
        "      if typ == \"M-MORPH\":\n",
        "        word += ch\n",
        "    except ValueError:\n",
        "      if word != '':\n",
        "        segmented_words.append(word.strip(\">\").replace(\">>\", \">\"))\n",
        "        word = ''\n",
        "      continue\n",
        "  if word != '':\n",
        "    segmented_words.append(word.strip(\">\").replace(\">>\", \">\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUQGVBka2MAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a74be36-82bc-46d2-dda7-8bd5ead834ba"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 15872\n",
            "drwxr-xr-x  1 root root    4096 Oct 11 21:37  .\n",
            "drwxr-xr-x  1 root root    4096 Oct 11 17:30  ..\n",
            "drwxr-xr-x  5 root root    4096 Oct 11 18:48  awd-lstm-lm\n",
            "drwxr-xr-x  1 root root    4096 Oct  5 16:31  .config\n",
            "drwxr-xr-x  2 root root    4096 Oct 11 21:37  corpora\n",
            "-rw-r--r--  1 root root     710 Oct 11 20:55  log.log\n",
            "drwxr-xr-x  4 root root    4096 Oct 11 18:43  low-resource-polysynthetic-morphology\n",
            "-rw-r--r--  1 root root 3099466 Oct 11 20:43  model1.bin\n",
            "-rw-r--r--  1 root root 3149296 Oct 11 20:49  model2.bin\n",
            "-rw-r--r--  1 root root 3217555 Oct 11 20:55  model3.bin\n",
            "-rw-r--r--  1 root root 2164117 Oct 11 20:55  model4.bin\n",
            "-rw-r--r--  1 root root 2163965 Oct 11 20:55  model5.bin\n",
            "-rw-r--r--  1 root root 2163965 Oct 11 20:55  model6.bin\n",
            "drwxr-xr-x 10 root root    4096 Oct 11 20:36  morfessor\n",
            "drwxr-xr-x  7 root root    4096 Oct 11 21:36  NCRFpp\n",
            "drwxr-xr-x 10 root root    4096 Oct 11 20:58  NeuralMorphemeSegmentation\n",
            "-rw-r--r--  1 root root   79479 Oct 11 20:37 'ru_standard_v4 (1)'\n",
            "-rw-r--r--  1 root root  147895 Oct 11 20:55  ru_standard_v4_anno\n",
            "drwxr-xr-x  1 root root    4096 Oct  5 16:31  sample_data\n",
            "drwxr-xr-x 12 root root    4096 Oct 11 21:37  segmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXgyQyXI2CHQ"
      },
      "source": [
        "with open(\"corpora/corpus_v5.txt\") as f:\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK9lzbt8ayrX"
      },
      "source": [
        "## Lguyogiro/low-resource-polysynthetic-morphology - currently have an issue with metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cx4ac12hxCe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0e48ffb6-70a2-4a5b-8892-2466bfe7f591"
      },
      "source": [
        "!git clone https://github.com/Lguyogiro/low-resource-polysynthetic-morphology.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'low-resource-polysynthetic-morphology'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI7PYq4ZDzqj",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a4026a39-0f3f-44f3-b389-4fa8915fca5e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3b85111-2b17-4201-a49b-a2667b62bc8f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3b85111-2b17-4201-a49b-a2667b62bc8f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving main.py to main.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaHDc4y5bdMd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5c627c91-c627-4f53-9f85-c5816c715cb3"
      },
      "source": [
        "!head ru_standard_v4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "гым>нин ытльа>т ы'ттъуви>∅ ынкъам о'мрытваал>∅\n",
            "пууръу эпы>∅ гым>нин о'м о'мрыквот>∅ нэмыӄэй ӄора>гынрэты>ль>о н>ит>ӄин\n",
            "гым>нин ытлыгы>т ытль'а>т>э ӄонпы эмнуӈ>кы ны>мигчир>эт>ӄинэ>т нэмыӄэй ӄора>гынрэты>ль>о нитӄинэт\n",
            "ынкъам мури га>чакэт>томг>а гэ гэ>егтэль>мури каврагыргы>н ынкъам гым\n",
            "ытръэч>е ӈирэӄ нэнэнэ>т ∅>ва>гъэ>т\n",
            "ытръэч\n",
            "кытур ынӈытэӄ>э мэдвэдэв>∅ прэзидэнт>о эн>ма канчалян>эты гэ>рэмкичи>льин\n",
            "ынкъа люут ӈыръа вэрталёт>тэ ∅>вакъо>гъа>т>ӈа\n",
            "ны>ны>пчеӈи>в>йив>ӄин колё нымным>а мэдвэдэв>∅>ъым\n",
            "гэчев>кы ны>нты>ӄин таӈ>колё ын>кы ны>гынрит>ӄин\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7cGZwOQ_VNH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5707ea7d-5297-41c3-9142-0952d091156d"
      },
      "source": [
        "!mv awd-lstm-lm/ru_standard_v4 ru_standard_v4 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'awd-lstm-lm/ru_standard_v4': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUjydxpVa8Jo"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train_w = open(\"low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_w.train\", \"w\")\n",
        "train_s = open(\"low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_s.train\", \"w\")\n",
        "dev_w = open(\"low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_w.dev\", \"w\")\n",
        "dev_s = open(\"low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_s.dev\", \"w\")\n",
        "data_w = []\n",
        "data_s = []\n",
        "\n",
        "data_w, data_s = shuffle(data_w, data_s, random_state=42)\n",
        "with open(\"ru_standard_v4\") as f:\n",
        "  for line in f.readlines():\n",
        "    if len(line) == 0:\n",
        "      continue\n",
        "    for word in line.split():\n",
        "      data_s.append(' '.join([c for c in word.replace('>', \"!\")]) + \"\\n\")\n",
        "      data_w.append(' '.join([c for c in word.replace(\">\", \"\").replace(\"∅\",\"\")]) + \"\\n\")\n",
        "divider = int(len(data_w)*0.9)\n",
        "train_w.writelines(data_w[:divider])\n",
        "dev_w.writelines(data_w[divider:])\n",
        "train_s.writelines(data_s[:divider])\n",
        "dev_s.writelines(data_s[divider:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCi_KeViEGpd"
      },
      "source": [
        "!mv low-resource-polysynthetic-morphology/neural_seq2seq/main.py low-resource-polysynthetic-morphology/neural_seq2seq/main_new_old.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIRorjnSEMwU"
      },
      "source": [
        "!mv main.py low-resource-polysynthetic-morphology/neural_seq2seq/main.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFAsUQrvcAKE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "13c92e1a-0745-4d03-aba7-0bd7ed3b3808"
      },
      "source": [
        "!head low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_w.train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "г ы м н и н\n",
            "ы т л ь а т\n",
            "ы ' т т ъ у в и\n",
            "ы н к ъ а м\n",
            "о ' м р ы т в а а л\n",
            "п у у р ъ у\n",
            "э п ы\n",
            "г ы м н и н\n",
            "о ' м\n",
            "о ' м р ы к в о т\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY1SkCBzcD9k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "83b89ff0-e6b2-41c4-fdc2-021779aefe3b"
      },
      "source": [
        "!head low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_s.train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "г ы м ! н и н\n",
            "ы т л ь а ! т\n",
            "ы ' т т ъ у в и ! ∅\n",
            "ы н к ъ а м\n",
            "о ' м р ы т в а а л ! ∅\n",
            "п у у р ъ у\n",
            "э п ы ! ∅\n",
            "г ы м ! н и н\n",
            "о ' м\n",
            "о ' м р ы к в о т ! ∅\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzzJ1T0gkQ4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "96e33fca-5c16-4dc9-bb07-c36f184579d1"
      },
      "source": [
        "!head low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_w.dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ы н ӄ о\n",
            "ы н ӄ о\n",
            "м ы т ъ и р м ы к э\n",
            "р о\n",
            "р о\n",
            "р о ч\n",
            "р о ч г э т ы\n",
            "ы н ӄ э н\n",
            "м и ӈ к ы\n",
            "н ы т в а ӄ э н\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gVIJNMUkQ7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1e74b605-4420-4f8c-be72-9f8df27860a8"
      },
      "source": [
        "!head low-resource-polysynthetic-morphology/neural_seq2seq/chkchn_s.dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ы н ӄ о\n",
            "ы н ӄ о\n",
            "м ы т ! ъ и р ! м ы к ! э\n",
            "р о\n",
            "р о\n",
            "р о ч\n",
            "р о ч г ! э т ы\n",
            "ы н ӄ э н\n",
            "м и ӈ ! к ы\n",
            "н ы ! т в а ! ӄ э н\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jOsmPy6euxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "5cac731e-1bbc-4c9d-8c91-f71fa74bf147"
      },
      "source": [
        "!cd low-resource-polysynthetic-morphology/neural_seq2seq && python main.py chkchn_w.train chkchn_s.train chkchn_w.dev chkchn_s.dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 2.191 | Train PPL:   8.941\n",
            "\t Val. Loss: 1.592 |  Val. PPL:   4.914\n",
            "Val Acc: 0.23627684964200477\n",
            "Val Prec: 0.0\n",
            "Val Rec: 0.0\n",
            "Val F score: 0\n",
            "Epoch: 02\n",
            "\tTrain Loss: 1.090 | Train PPL:   2.974\n",
            "\t Val. Loss: 1.239 |  Val. PPL:   3.450\n",
            "Val Acc: 0.3412887828162291\n",
            "Val Prec: 0.0\n",
            "Val Rec: 0.0\n",
            "Val F score: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJI40L0rEavk"
      },
      "source": [
        "!cd low-resource-polysynthetic-morphology/neural_seq2seq && sed -i 's/from neural_seq2seq.models import Encoder, Decoder, Seq2Seq, Attention/from models import Encoder, Decoder, Seq2Seq, Attention/g' main.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSvFQXyhe3HX"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxzbTzMkkmXB",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "2c909deb-0604-471d-f1a6-d5bcb258ffec"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-09f9e03a-c0f4-41e7-8e13-76b5322d7a3b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-09f9e03a-c0f4-41e7-8e13-76b5322d7a3b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAtTy-rJA2pL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e08d8939-416a-4eda-e4e9-53ce3d0e2332"
      },
      "source": [
        "!head awd-lstm-lm/train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ыны>к ытлыгин ны>мытва>томг>о рытчы>ни>н\n",
            "пээг>ти гэ>въил>ин наӄам тумгы>т ымыльо ӈэлвы>льы>к тэгмэчын>кы га>ё>ъоръо>лен наӄам ӈэлвыл ам>мана>ӈ гэ>рит>ле>лин\n",
            "мэмыл ванэван ны>ра>ра>гты>ӈы>н ванэван ны>ра>пааӈы>н чемгъо>тва>к кэӈ>ъири нэмэ аʔткэв>ма ны>тва>ӄэн нэмэ ытлён брига>да>к тъэӄэ>лтэт>лин\n",
            "н>авэръыерэ>гыт ви вай\n",
            "иты>к лыг>ъэт>ки>ӈ ээ миӈ>кы>ри>ым ва>льы>н миӈ>кы>ри нынт>игыт\n",
            "ӄээӄын ты>ттэт>гъ>и таа>лгыл>ят>гъэ ыʔтвы>ӈӄача>гты ыʔтвы>льы>н эвын ӈан>ӄэн\n",
            "нэнэнэ>т ва>льо\n",
            "ны>мэт>ивэт>ӄин аʔаче>к гына>ным\n",
            "нутэс>ӄыным\n",
            "ив>ни>н ив>ни>н ӈэвъэн>йыръ>э с аʔмын>ым\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmOphJjchGyC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f101526a-c0fa-490a-da33-7275ec7e433f"
      },
      "source": [
        "# embs from iiksiin - https://github.com/neural-polysynthetic-language-modelling/iiksiin\n",
        "\n",
        "import pickle\n",
        "import numpy\n",
        "\n",
        "text = \"\"\n",
        "with open('train.txt') as f:\n",
        "    text = f.read()\n",
        "\n",
        "res = []\n",
        "\n",
        "already_taken = {}\n",
        "unique = 0\n",
        "\n",
        "with open('chukchi.vectors', 'rb') as f:\n",
        "    emb_dict = pickle.load(f, encoding='utf8')\n",
        "    \n",
        "    for sent in text.split(\"\\n\"):\n",
        "        for word in sent.split():\n",
        "            for segm in word.split(\">\"):\n",
        "                if len(segm) == 0:\n",
        "                    continue\n",
        "                try:\n",
        "                    _ = already_taken[segm]\n",
        "                    continue\n",
        "                except KeyError:\n",
        "                    try:\n",
        "                        vect = emb_dict[segm]\n",
        "                        res.append(vect)\n",
        "                    except KeyError:\n",
        "                        unique += 1\n",
        "                        vect = numpy.array([0.0] * 64)\n",
        "                        for char in list(segm):\n",
        "                            try:\n",
        "                                c_vect = numpy.array(emb_dict[char])\n",
        "                                vect += c_vect\n",
        "                            except KeyError:\n",
        "                                continue\n",
        "                        vect /= len(list(segm))\n",
        "                        res.append(vect.tolist())\n",
        "                    already_taken[segm] = True\n",
        "\n",
        "print(len(res), unique)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14172 8090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScN1gBP21jEJ"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('test', 'w') as f:\n",
        "  json.dump(res, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgSz5Cxi2QRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bd45519-6641-4ebe-adb4-04f8b1533938"
      },
      "source": [
        "with open('test', 'r') as f:\n",
        "  data_r = json.load(f)\n",
        "\n",
        "data_r == res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G2fVkUY2GOD"
      },
      "source": [
        "!head test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZD2eWjre-Nm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8b61fb5e-f1a0-4a2e-9926-08d791c623ef"
      },
      "source": [
        "!head corpus_as_standard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "А>маравкэ>вара>тэн таа>’ко>йн’ы>н\n",
            "Йъйык'ы>к ны>к'эл>пэрат>к'эн вы>тэчгытры>к'эргы>льы>н йын'эт>тэ>т\n",
            "Мы>кы>н' ны>вытрэт>к'ин челга>твытры>льо ынк'оры>-ым вы>тэчгытры>льо\n",
            "Ынк'оры>-ым ны>к'эргавы>н'о>к'эн ны>чел>гъа>в\n",
            "Ы'льыл>е ыннаны гэн>ни>н'эв>лин а>эро>дро>м э>лгы>къале>йпы>гъа>т пылвынты>мытк'ы>ёчгыт эвы>р от>ты>рак'аг>тэ ы'льыл нэмык'эй к'ынур а>малва>н' ны>нъэл>к'ин ны>челг>ат>к'эн ны>вытэчгытра>т>к'эн\n",
            "Аэродро>мык рыма>гты н>увпэра>к'эн гытгы>н пытк'ы рыма>гты ны>вытрэт>к'инэ>т ма>ёлгыт\n",
            "Ынн'ытэ>к' на>к'ам чит га>кыткыт>ръо>лен маё>лгэ>пы г>апы>льы>ль>аты>н'о>лена>т в>ээм>к'эг>ти ы'льыл га>тылгы>н'н'о>лен гытгы>н эн>мэч уйн'э э>гилкэ гэн>ъэт>лин\n",
            "Люур нэмэ мач>чьа>ча>н'>аты>н'о>гъэ эн>мэч н'ыро>нъылё>к лё>н'>паата пин'>эты>к к'ынур нэмэ льэле>н'ръу>гъи э'квырга-ым гытгын к'он>пы га>паа>лен к'иты>к\n",
            "га>тылгы>н'н'о>лен гытгы>н эн>мэч уйн'э э>гилкэ гэн>ъэт>лин\n",
            "Люур нэмэ мач>чьа>ча>н'>аты>н'о>гъэ эн>мэч н'ыро>нъылё>к лё>н'>паата пин'>эты>к к'ынур нэмэ льэле>н'ръу>гъи э'квырга-ым гытгын к'он>пы га>паа>лен к'иты>к\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u2P3SO_gez8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c374ae0c-2290-4523-b98e-de934de9faaa"
      },
      "source": [
        "!head corpus_v4.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Амаравкэваратэн таа’койӈын.\n",
            "Йъйыӄык ныӄэлпэратӄэн вытэчгытрыӄэргыльын йыӈэттэт.\n",
            "Мыкыӈ нывытрэтӄин челгатвытрыльо, ынӄоры-ым вытэчгытрыльо.\n",
            "Ынӄоры-ым ныӄэргавыӈоӄэн нычелгъав.\n",
            "Ы'льыле ыннаны гэнниӈэвлин аэродром, элгыкъалейпыгъат пылвынтымытӄыёчгыт эвыр оттыраӄагтэ, ы'льыл нэмыӄэй ӄынур амалваӈ нынъэлӄин: нычелгатӄэн, нывытэчгытратӄэн.\n",
            "Аэродромык рымагты нувпэраӄэн гытгын, пытӄы рымагты нывытрэтӄинэт маёлгыт.\n",
            "Ынӈытэӄ наӄам чит гакыткытръолен, маёлгэпы гапыльыльатыӈоленат вээмӄэгти, ы'льыл гатылгыӈӈолен, гытгын энмэч уйӈэ эгилкэ гэнъэтлин.\n",
            "Люур нэмэ маччьачаӈатыӈогъэ, энмэч ӈыронъылёк лёӈпаата пиӈэтык, ӄынур нэмэ льэлеӈръугъи, э'квырга-ым гытгын ӄонпы гапаален ӄитык.\n",
            "гатылгыӈӈолен, гытгын энмэч уйӈэ эгилкэ гэнъэтлин.\n",
            "Люур нэмэ маччьачаӈатыӈогъэ, энмэч ӈыронъылёк лёӈпаата пиӈэтык, ӄынур нэмэ льэлеӈръугъи, э'квырга-ым гытгын ӄонпы гапаален ӄитык.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw2m60X5f3VT"
      },
      "source": [
        "# w2v embs for not segmented\n",
        "import gensim\n",
        "from string import punctuation\n",
        "\n",
        "punct = punctuation+'«»—…“”*№–'\n",
        "def normalize(text):\n",
        "    return ' '.join([word.strip(punct) for word in text.lower().split()])\n",
        "\n",
        "data = open(\"corpus_v4.txt\").readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-o3uZori6B3"
      },
      "source": [
        "data_norm = [normalize(s) for s in data]\n",
        "data_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzLzSeVEi2_Q"
      },
      "source": [
        "w2v_not_segm = gensim.models.Word2Vec([text.split() for text in data_norm], size=50, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9foNjTXNkN2H"
      },
      "source": [
        "with open('w2v_not_segm', 'rb') as f:\n",
        "    emb_dict = pickle.load(f, encoding='utf8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9AOhKIzkbez"
      },
      "source": [
        "w2v_not_segm.wv.save_word2vec_format(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdUrCJOxlVq_"
      },
      "source": [
        "!head test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHn_d0hugjm0"
      },
      "source": [
        "# w2v embs for segmented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgFLf92DmVcw"
      },
      "source": [
        "def normalize_segm(text):\n",
        "    return ' '.join([word.strip(punct_segm) for word in text.lower().replace(\">\", \" \").split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqq8YL2Zgqqy"
      },
      "source": [
        "data_segm = open(\"corpus_as_standard\").readlines()\n",
        "for s in data_segm:\n",
        "  s = s.lower()\n",
        "data_segm_norm = [normalize_segm(s) for s in data_segm]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N1yt5PVmsPs"
      },
      "source": [
        "w2v_segm = gensim.models.Word2Vec([text.split() for text in data_segm_norm], size=50, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHWhsOcPnET4"
      },
      "source": [
        "w2v_segm.wv.save_word2vec_format(\"test2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S054sKhKnJ6d"
      },
      "source": [
        "!head -n 25 test2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fug1nieHnLqZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9qtoMCCSTBw"
      },
      "source": [
        "# Language modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVopJlSoSSck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "24dd4e51-8868-47b5-804b-dd4bd18238cd"
      },
      "source": [
        "!git clone https://github.com/lwahomura/awd-lstm-lm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'awd-lstm-lm'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 246 (delta 11), reused 16 (delta 6), pack-reused 224\u001b[K\n",
            "Receiving objects: 100% (246/246), 89.88 KiB | 303.00 KiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2T5WAdWnvkL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "70f8cba8-c1fe-4979-a26b-489b8e4df915"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/lwahomura/awd-lstm-lm\n",
            "   cd3e4bd..765fabf  master     -> origin/master\n",
            "Updating cd3e4bd..765fabf\n",
            "Fast-forward\n",
            " data.py | 6 \u001b[32m+++++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 5 insertions(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M16pIQbZTTVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2ec0954-0c82-4287-d73c-564ba63027eb"
      },
      "source": [
        "%cd awd-lstm-lm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/awd-lstm-lm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxnLwdLgSW2D"
      },
      "source": [
        "with open(\"data/train.txt\", \"w\") as f:\n",
        "  for i in range(0, 800):\n",
        "    if i%100 == 0 and i != 0:\n",
        "      f.write(\"\\n\")\n",
        "    if i%2 == 0:\n",
        "      f.write(\"a \")\n",
        "    if i%2 == 1:\n",
        "      f.write(\"b \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51f3u4PsS-sZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a0b96abe-ce84-4dda-ec8c-d6ed1caf2ce7"
      },
      "source": [
        "!head data/train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b \n",
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b \n",
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b \n",
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b \n",
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b \n",
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b \n",
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b \n",
            "a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUGd-eUdTBGg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "3ad3fbde-43ac-4271-e7e3-e72acac55174"
      },
      "source": [
        "!pip install torch==0.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K     |████████████████████████████████| 484.0MB 36kB/s \n",
            "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed torch-0.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEYDwvWwtUQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2e617a1-b5ee-42a8-8a87-9a262e681de5"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVdKFkCztA0Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d336a22b-3f17-4215-f27d-1b6bd9693ead"
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVyd_v9xT_6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "86274277-f623-40e9-efb3-a4f64833fd98"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 124\n",
            "drwxr-xr-x 5 root root  4096 Oct 11 17:22 .\n",
            "drwxr-xr-x 1 root root  4096 Oct 11 15:40 ..\n",
            "drwxr-xr-x 3 root root  4096 Oct 11 17:08 data\n",
            "-rw-r--r-- 1 root root  1965 Oct 11 17:22 data.py\n",
            "-rw-r--r-- 1 root root  1001 Oct 11 15:31 embed_regularize.py\n",
            "-rw-r--r-- 1 root root 10068 Oct 11 15:31 finetune.py\n",
            "-rw-r--r-- 1 root root  3346 Oct 11 15:31 generate.py\n",
            "-rwxr-xr-x 1 root root  1434 Oct 11 15:31 getdata.sh\n",
            "drwxr-xr-x 8 root root  4096 Oct 11 17:22 .git\n",
            "-rw-r--r-- 1 root root    18 Oct 11 15:31 .gitignore\n",
            "-rw-r--r-- 1 root root  1500 Oct 11 15:31 LICENSE\n",
            "-rw-r--r-- 1 root root   454 Oct 11 15:31 locked_dropout.py\n",
            "-rw-r--r-- 1 root root 13074 Oct 11 17:17 main.py\n",
            "-rw-r--r-- 1 root root  4863 Oct 11 15:31 model.py\n",
            "-rw-r--r-- 1 root root  5676 Oct 11 15:31 pointer.py\n",
            "drwxr-xr-x 2 root root  4096 Oct 11 17:17 __pycache__\n",
            "-rw-r--r-- 1 root root 10685 Oct 11 15:31 README.md\n",
            "-rw-r--r-- 1 root root  9995 Oct 11 15:31 splitcross.py\n",
            "-rw-r--r-- 1 root root   977 Oct 11 17:13 utils.py\n",
            "-rw-r--r-- 1 root root  3237 Oct 11 15:31 weight_drop.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-49UOq1piWv"
      },
      "source": [
        "!rm corpus.8d777f385d3dfec8815d20f7496026dc.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flVUvuB6TWIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0177971f-3eec-487a-84f2-de29071e9356"
      },
      "source": [
        "!python -W ignore -u main.py --epochs 20 --nlayers 3 --emsize 64 --nhid 1840 --alpha 0 --beta 0 --dropoute 0 --dropouth 0.1 --dropouti 0.1 --dropout 0.4 --wdrop 0.2 --wdecay 1.2e-6 --bptt 200 --batch_size 20 --optimizer adam --lr 1e-3 --data data --save CHUKCHI_CHARS.pt --when 25 35 --cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Producing dataset...\n",
            "creating tokens tensor on cuda\n",
            "created tokens tensor on cuda\n",
            "creating tokens tensor on cuda\n",
            "created tokens tensor on cuda\n",
            "creating tokens tensor on cuda\n",
            "created tokens tensor on cuda\n",
            "Got dataset\n",
            "moving data to cuda\n",
            "moved data to cuda\n",
            "moving data to cuda\n",
            "moved data to cuda\n",
            "moving data to cuda\n",
            "moved data to cuda\n",
            "Creating model\n",
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "[WeightDrop(\n",
            "  (module): LSTM(64, 1840)\n",
            "), WeightDrop(\n",
            "  (module): LSTM(1840, 1840)\n",
            "), WeightDrop(\n",
            "  (module): LSTM(1840, 64)\n",
            ")]\n",
            "Created model\n",
            "Using []\n",
            "Moved model to cuda\n",
            "Args: Namespace(alpha=0.0, batch_size=20, beta=0.0, bptt=200, clip=0.25, cuda=True, data='data', dropout=0.4, dropoute=0.0, dropouth=0.1, dropouti=0.1, emsize=64, epochs=20, log_interval=200, lr=0.001, model='LSTM', nhid=1840, nlayers=3, nonmono=5, optimizer='adam', resume='', save='CHUKCHI_CHARS.pt', seed=1111, tied=True, wdecay=1.2e-06, wdrop=0.2, when=[25, 35])\n",
            "Model total parameters: 41615811\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time:  0.08s | valid loss  0.96 | valid ppl     2.62 | valid bpc    1.391\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time:  0.07s | valid loss  0.89 | valid ppl     2.45 | valid bpc    1.290\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time:  0.07s | valid loss  0.83 | valid ppl     2.30 | valid bpc    1.204\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time:  0.08s | valid loss  0.79 | valid ppl     2.19 | valid bpc    1.134\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time:  0.07s | valid loss  0.75 | valid ppl     2.11 | valid bpc    1.079\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time:  0.07s | valid loss  0.72 | valid ppl     2.05 | valid bpc    1.038\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time:  0.08s | valid loss  0.70 | valid ppl     2.02 | valid bpc    1.012\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time:  0.08s | valid loss  0.69 | valid ppl     2.00 | valid bpc    0.998\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time:  0.08s | valid loss  0.69 | valid ppl     1.98 | valid bpc    0.989\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time:  0.07s | valid loss  0.68 | valid ppl     1.97 | valid bpc    0.978\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time:  0.07s | valid loss  0.67 | valid ppl     1.96 | valid bpc    0.971\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time:  0.07s | valid loss  0.67 | valid ppl     1.95 | valid bpc    0.967\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time:  0.08s | valid loss  0.67 | valid ppl     1.95 | valid bpc    0.964\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time:  0.08s | valid loss  0.67 | valid ppl     1.95 | valid bpc    0.965\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time:  0.08s | valid loss  0.67 | valid ppl     1.95 | valid bpc    0.967\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time:  0.07s | valid loss  0.67 | valid ppl     1.95 | valid bpc    0.966\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time:  0.07s | valid loss  0.66 | valid ppl     1.94 | valid bpc    0.959\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time:  0.07s | valid loss  0.66 | valid ppl     1.93 | valid bpc    0.951\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time:  0.07s | valid loss  0.66 | valid ppl     1.93 | valid bpc    0.946\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time:  0.07s | valid loss  0.65 | valid ppl     1.92 | valid bpc    0.942\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "=========================================================================================\n",
            "| End of training | test loss  0.72 | test ppl     2.06 | test bpc    1.044\n",
            "=========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qAJ6tckk0s8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ce5e3c94-616f-4193-a24f-d4f65beabf16"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 311296\n",
            "drwxr-xr-x 5 root root      4096 Oct 11 17:54 .\n",
            "drwxr-xr-x 1 root root      4096 Oct 11 17:40 ..\n",
            "-rw-r--r-- 1 root root 282622801 Oct 11 17:42 CHUKCHI_CHARS.pt\n",
            "-rw-r--r-- 1 root root  16530359 Oct 11 17:50 chukchi.vectors\n",
            "-rw-r--r-- 1 root root     10455 Oct 11 17:41 corpus.8d777f385d3dfec8815d20f7496026dc.data\n",
            "-rw-r--r-- 1 root root   2803986 Oct 11 17:52 corpus_as_standard\n",
            "drwxr-xr-x 3 root root      4096 Oct 11 17:40 data\n",
            "-rw-r--r-- 1 root root      1965 Oct 11 17:40 data.py\n",
            "-rw-r--r-- 1 root root      1001 Oct 11 17:40 embed_regularize.py\n",
            "-rw-r--r-- 1 root root     10068 Oct 11 17:40 finetune.py\n",
            "-rw-r--r-- 1 root root      3346 Oct 11 17:40 generate.py\n",
            "-rwxr-xr-x 1 root root      1434 Oct 11 17:40 getdata.sh\n",
            "drwxr-xr-x 8 root root      4096 Oct 11 17:40 .git\n",
            "-rw-r--r-- 1 root root        18 Oct 11 17:40 .gitignore\n",
            "-rw-r--r-- 1 root root      1500 Oct 11 17:40 LICENSE\n",
            "-rw-r--r-- 1 root root       454 Oct 11 17:40 locked_dropout.py\n",
            "-rw-r--r-- 1 root root     13074 Oct 11 17:40 main.py\n",
            "-rw-r--r-- 1 root root      4863 Oct 11 17:40 model.py\n",
            "-rw-r--r-- 1 root root      5676 Oct 11 17:40 pointer.py\n",
            "drwxr-xr-x 2 root root      4096 Oct 11 17:41 __pycache__\n",
            "-rw-r--r-- 1 root root     10685 Oct 11 17:40 README.md\n",
            "-rw-r--r-- 1 root root     79479 Oct 11 17:52 ru_standard_v4\n",
            "-rw-r--r-- 1 root root      9995 Oct 11 17:40 splitcross.py\n",
            "-rw-r--r-- 1 root root  14961520 Oct 11 18:07 test\n",
            "-rw-r--r-- 1 root root   1618606 Oct 11 17:53 train.txt\n",
            "-rw-r--r-- 1 root root       977 Oct 11 17:40 utils.py\n",
            "-rw-r--r-- 1 root root      3237 Oct 11 17:40 weight_drop.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFJ8jurc8s4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}